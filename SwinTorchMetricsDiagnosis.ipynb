{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVHZ8OFy8dl2",
        "outputId": "3ca4e41a-2d00-4c34-b939-8e2595a82992"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu May 19 12:24:23 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 512.77       Driver Version: 512.77       CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
            "| 31%   58C    P0    71W / 300W |   3126MiB / 11264MiB |      5%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A      4196    C+G   ...e\\root\\Office16\\EXCEL.EXE    N/A      |\n",
            "|    0   N/A  N/A      5900    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
            "|    0   N/A  N/A      8292    C+G   ...32\\backgroundTaskHost.exe    N/A      |\n",
            "|    0   N/A  N/A     10396    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
            "|    0   N/A  N/A     11408    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
            "|    0   N/A  N/A     11452    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A     14084    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
            "|    0   N/A  N/A     14556    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
            "|    0   N/A  N/A     15124    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
            "|    0   N/A  N/A     16968    C+G   ...obeNotificationClient.exe    N/A      |\n",
            "|    0   N/A  N/A     17484    C+G   ...root\\Office16\\WINWORD.EXE    N/A      |\n",
            "|    0   N/A  N/A     17692    C+G   ...in7x64\\steamwebhelper.exe    N/A      |\n",
            "|    0   N/A  N/A     19380    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A     20316    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
            "|    0   N/A  N/A     21660    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
            "|    0   N/A  N/A     21700    C+G   ...\\app-1.0.9004\\Discord.exe    N/A      |\n",
            "|    0   N/A  N/A     22296    C+G   ...aming\\Spotify\\Spotify.exe    N/A      |\n",
            "|    0   N/A  N/A     22516    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
            "|    0   N/A  N/A     23076    C+G   ...les (x86)\\Steam\\steam.exe    N/A      |\n",
            "|    0   N/A  N/A     23668    C+G   ...t\\Teams\\current\\Teams.exe    N/A      |\n",
            "|    0   N/A  N/A     24732    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
            "|    0   N/A  N/A     26948    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
            "|    0   N/A  N/A     28804    C+G   ...Launcher\\UplayWebCore.exe    N/A      |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "id": "byXxUcDI-BLR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "#Problem params\n",
        "numClasses = 1000\n",
        "realClassNumber = 2\n",
        "if realClassNumber > 2:\n",
        "  binaryClassification = False\n",
        "else:\n",
        "  binaryClassification = True\n",
        "\n",
        "imageSizePx = 224#224\n",
        "window_Size = int(7*(imageSizePx/224))\n",
        "\n",
        "\n",
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)\n",
        "\n",
        "if device == \"cuda\":\n",
        "  batchSize = 8#64 #224:64, 448:8, 672:2\n",
        "else:\n",
        "  batchSize = 32\n",
        "\n",
        "#best for each model\n",
        "#DR test\n",
        "\n",
        "pretrainedPath = r'E:\\models\\diagnosis\\G30-G32_Other_degenerative_diseases_of_nervous_system\\swin_tiny_patch4_window7_224\\ImageNetMoBy224\\ckpt_epoch_4.pth'\n",
        "\n",
        "#Top-1 models\n",
        "#IMGNET SUPER 224 '/content/drive/MyDrive/Colab Notebooks/FYP/MOBY SSL SWIN/swin_tiny_patch4_window7_224/ImageNetSupervisedPretrained224/ckpt_epoch_45.pth'\n",
        "#random 224 \"/content/drive/MyDrive/Colab Notebooks/FYP/MOBY SSL SWIN/swin_tiny_patch4_window7_224/RandomInit224/ckpt_epoch_49.pth\"\n",
        "#ImageNet MOBY \"/content/drive/MyDrive/Colab Notebooks/FYP/MOBY SSL SWIN/swin_tiny_patch4_window7_224/ImageNetUnsupervisedPretrainMOBY224/ckpt_epoch_49.pth\"\n",
        "#MineMOBY224 \"/content/drive/MyDrive/Colab Notebooks/FYP/MOBY SSL SWIN/swin_tiny_patch4_window7_224/MineUnsupervisedPretrainMOBY224/ckpt_epoch_130.pth\"\n",
        "#MineMOBY448 \"/content/drive/MyDrive/Colab Notebooks/FYP/MOBY SSL SWIN/swin_tiny_patch4_window7_224/MineUnsupervisedPretrainMOBY448/ckpt_epoch_18.pth\"\n",
        "#672 \"/content/drive/MyDrive/Colab Notebooks/FYP/MOBY SSL SWIN/swin_tiny_patch4_window7_224/MineUnsupervisedPretrainMOBY672/ckpt_epoch_10.pth\"\n",
        "\n",
        "#lowest loss\n",
        "\n",
        "#-----------\n",
        "#Ch_IX_Diseases_of_Circulatory_System\n",
        "#imagenetsuper r'E:\\models\\diagnosis\\Ch_IX_Diseases_of_Circulatory_System\\swin_tiny_patch4_window7_224\\ImageNetSupervised224\\ckpt_epoch_35.pth'\n",
        "#imagenetmoby r'E:\\models\\diagnosis\\Ch_IX_Diseases_of_Circulatory_System\\swin_tiny_patch4_window7_224\\ImageNetMoBy224\\ckpt_epoch_40.pth'\n",
        "# project  r'E:\\models\\diagnosis\\Ch_IX_Diseases_of_Circulatory_System\\swin_tiny_patch4_window7_224\\MineMOBY224\\ckpt_epoch_47.pth'\n",
        "\n",
        "#Chapter VI Diseases of the Nervous System\n",
        "#imagenetsuper r'E:\\models\\diagnosis\\Ch_VI_DiseasesOfNervousSystem\\swin_tiny_patch4_window7_224\\ImageNetSupervised224\\ckpt_epoch_26.pth'\n",
        "#imagenetmoby r'E:\\models\\diagnosis\\Ch_VI_DiseasesOfNervousSystem\\swin_tiny_patch4_window7_224\\ImageNetMoBy224\\ckpt_epoch_33.pth'\n",
        "# project  r'E:\\models\\diagnosis\\Ch_VI_DiseasesOfNervousSystem\\swin_tiny_patch4_window7_224\\MineMOBY224\\ckpt_epoch_49.pth'\n",
        "\n",
        "#G30-G32 Other degenerative diseases of the nervous system \n",
        "#imagenetsuper r'E:\\models\\diagnosis\\G30-G32_Other_degenerative_diseases_of_nervous_system\\swin_tiny_patch4_window7_224\\ImageNetSupervised224\\ckpt_epoch_49.pth'\n",
        "#imagenetmoby r'E:\\models\\diagnosis\\G30-G32_Other_degenerative_diseases_of_nervous_system\\swin_tiny_patch4_window7_224\\ImageNetMoBy224\\ckpt_epoch_5.pth'\n",
        "# project  r'E:\\models\\diagnosis\\G30-G32_Other_degenerative_diseases_of_nervous_system\\swin_tiny_patch4_window7_224\\MineMOBY224\\ckpt_epoch_9.pth'\n",
        "\n",
        "#I10-I15 Hypertensive diseases \n",
        "#imagenetsuper r'E:\\models\\diagnosis\\I10-I15_Hypertensive_diseases\\swin_tiny_patch4_window7_224\\ImageNetSupervised224\\ckpt_epoch_45.pth'\n",
        "#imagenetmoby r'E:\\models\\diagnosis\\I10-I15_Hypertensive_diseases\\swin_tiny_patch4_window7_224\\ImageNetMoBy224\\ckpt_epoch_46.pth'\n",
        "# project  r'E:\\models\\diagnosis\\I10-I15_Hypertensive_diseases\\swin_tiny_patch4_window7_224\\MineMOBY224\\ckpt_epoch_42.pth'\n",
        "\n",
        "#I60-I69 Cerebrovascular diseases \n",
        "#imagenetsuper r'E:\\models\\diagnosis\\I60-I69_Cerebrovascular_diseases\\swin_tiny_patch4_window7_224\\ImageNetSupervised224\\ckpt_epoch_26.pth'\n",
        "#imagenetmoby r'E:\\models\\diagnosis\\I60-I69_Cerebrovascular_diseases\\swin_tiny_patch4_window7_224\\ImageNetMoBy224\\ckpt_epoch_47.pth'\n",
        "# project  r'E:\\models\\diagnosis\\I60-I69_Cerebrovascular_diseases\\swin_tiny_patch4_window7_224\\MineMOBY224\\ckpt_epoch_1.pth'\n",
        "\n",
        "#I80-I89 Diseases of veins, lymphatic vessels and nodes \n",
        "#imagenetsuper r'E:\\models\\diagnosis\\I80-I89_Diseases_of_veins_lymphatic_vessels_and_nodes\\swin_tiny_patch4_window7_224\\ImageNetSupervised224\\ckpt_epoch_47.pth'\n",
        "#imagenetmoby r'E:\\models\\diagnosis\\I80-I89_Diseases_of_veins_lymphatic_vessels_and_nodes\\swin_tiny_patch4_window7_224\\ImageNetMoBy224\\ckpt_epoch_32.pth'\n",
        "# project  r'E:\\models\\diagnosis\\I80-I89_Diseases_of_veins_lymphatic_vessels_and_nodes\\swin_tiny_patch4_window7_224\\MineMOBY224\\ckpt_epoch_45.pth'\n",
        "\n",
        "#N17-N19 Renal failure\n",
        "#imagenetsuper r'E:\\models\\diagnosis\\N17-N19_Renal_failure\\swin_tiny_patch4_window7_224\\ImageNetSupervised224\\ckpt_epoch_39.pth'\n",
        "#imagenetmoby r'E:\\models\\diagnosis\\N17-N19_Renal_failure\\swin_tiny_patch4_window7_224\\ImageNetMoBy224\\ckpt_epoch_41.pth'\n",
        "# project  r'E:\\models\\diagnosis\\N17-N19_Renal_failure\\swin_tiny_patch4_window7_224\\MineMOBY224\\ckpt_epoch_1.pth'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUsYlqUsK3t-"
      },
      "source": [
        "#Download dummy dataset and load csv\n",
        "Change data format to class folder stucture train & val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bJKX7XwKpAP",
        "outputId": "bc864e67-ccad-45d0-c7cb-07aad5775cb3"
      },
      "outputs": [],
      "source": [
        "with open('kaggle.json', 'w') as writefile:\n",
        "    writefile.write('''{\"username\":\"gilescodes\",\"key\":\"f79796044c43da415594ce39514bc230\"}''')\n",
        "\n",
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! mkdir competitionKaggle\n",
        "! pip install --upgrade --force-reinstall --no-deps kaggle\n",
        "\n",
        "#https://www.kaggle.com/benjaminwarner/resized-2015-2019-blindness-detection-images\n",
        "!kaggle datasets download -p /content/competitionKaggle/ -d benjaminwarner/resized-2015-2019-blindness-detection-images\n",
        "\n",
        "!unzip /content/competitionKaggle/resized-2015-2019-blindness-detection-images.zip -d /content/competitionKaggle/\n",
        "!rm /content/competitionKaggle/resized-2015-2019-blindness-detection-images.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCrlcBfkM3ku"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train = pd.read_csv(\"/content/competitionKaggle/labels/trainLabels15.csv\")#\"/content/competitionKaggle/trainLabels.csv\")#\"../input/com3025-2022-image-classification-challenge/train.csv\"\n",
        "train = train.astype('string')\n",
        "\n",
        "test = pd.read_csv(\"/content/competitionKaggle/labels/testLabels15.csv\")#\"/content/competitionKaggle/trainLabels.csv\")#\"../input/com3025-2022-image-classification-challenge/train.csv\"\n",
        "test = test.astype('string')\n",
        "\n",
        "train2 = pd.read_csv(\"/content/competitionKaggle/labels/trainLabels19.csv\")#\"/content/competitionKaggle/trainLabels.csv\")#\"../input/com3025-2022-image-classification-challenge/train.csv\"\n",
        "train2 = train2.astype('string')\n",
        "\n",
        "\n",
        "def append_ext(fn):#add file extention to filenames\n",
        "    return fn+\".jpg\"#\".jpeg\"#check converted file extention\n",
        "\n",
        "train[\"image\"]=train[\"image\"].apply(append_ext)\n",
        "\n",
        "test[\"image\"]=test[\"image\"].apply(append_ext)\n",
        "\n",
        "train2[\"id_code\"]=train2[\"id_code\"].apply(append_ext)\n",
        "\n",
        "#SAMPLE SMALLER FOR QUICK RUNS --------------------------------------------------------------------------------------------------------------------------------------------\n",
        "#and making demo dataset\n",
        "# train = train.sample(1000)\n",
        "# test = test.sample(1000)\n",
        "# train2 = train2.sample(1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X36d4CxTN4Js"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/competitionKaggle/train\n",
        "!mkdir /content/competitionKaggle/val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFqxtwAOKLWn"
      },
      "outputs": [],
      "source": [
        "#very quick\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def createFolderTreeFromDataframe(df, folder, source, ycolumn, imageCol):\n",
        "  for index, row in df.iterrows():#for every row\n",
        "    image_class = row[ycolumn]#load the class\n",
        "    if not os.path.exists(f'/content/competitionKaggle/{folder}/{image_class}'):#create class folder if it doesnt exist\n",
        "      os.makedirs(f'/content/competitionKaggle/{folder}/{image_class}')\n",
        "    image_name = row[imageCol]#load the filename\n",
        "    shutil.move(f\"/content/competitionKaggle/{source}/{image_name}\", f\"/content/competitionKaggle/{folder}/{image_class}/\")#move that file to the new dest\n",
        "\n",
        "createFolderTreeFromDataframe(train, \"train\", \"resized train 15\",'level', 'image')\n",
        "createFolderTreeFromDataframe(test, \"train\", \"resized test 15\",'level', 'image')#put test in train as well\n",
        "createFolderTreeFromDataframe(train2, \"train\", \"resized train 19\", 'diagnosis', 'id_code')#put test in train as well\n",
        "#92364 total images\n",
        "\n",
        "# createFolderTreeFromDataframe(test, \"val\", \"resized test 15\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTRpM53diRgE"
      },
      "outputs": [],
      "source": [
        "#----------------------put 20% of images in val\n",
        "import os\n",
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "for i in range(5):\n",
        "  files = os.listdir(f\"/content/competitionKaggle/train/{i}\")\n",
        "  random.shuffle(files)\n",
        "  files = files[:int(len(files)*0.2)]\n",
        "  for fileName in files:\n",
        "    if not os.path.exists(f'/content/competitionKaggle/val/{i}'):#create class folder if it doesnt exist\n",
        "      os.makedirs(f'/content/competitionKaggle/val/{i}')\n",
        "    shutil.move(f\"/content/competitionKaggle/train/{i}/{fileName}\", f\"/content/competitionKaggle/val/{i}/\")#move that file to the new dest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WB8ApmUK6hzc"
      },
      "source": [
        "##make demo datset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Rajm3GE4xKB"
      },
      "outputs": [],
      "source": [
        "#move val and train to new dataset folder\n",
        "# !mkdir /content/competitionKaggle/demodataset\n",
        "# !mv /content/competitionKaggle/train /content/competitionKaggle/demodataset\n",
        "# !mv /content/competitionKaggle/val /content/competitionKaggle/demodataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQaXwsCA4NDt"
      },
      "outputs": [],
      "source": [
        "# #making demo dataset - delete after and not run again\n",
        "# !kaggle datasets init -p /content/competitionKaggle/demodataset\n",
        "# #change json metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImEVLwDW4i99"
      },
      "outputs": [],
      "source": [
        "# !kaggle datasets create -p /content/competitionKaggle/demodataset/ --dir-mode zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-eypuoz3Mbm"
      },
      "source": [
        "#Load data using dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "szsk7j9d3itH"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "wyewMHgT6Ahj"
      },
      "outputs": [],
      "source": [
        "#Image norm transform\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "IMAGENET_DEFAULT_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_DEFAULT_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "NORMtransform = transforms.Compose([\n",
        "    transforms.Resize((imageSizePx, imageSizePx)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=IMAGENET_DEFAULT_MEAN, std=IMAGENET_DEFAULT_STD),\n",
        "])\n",
        "\n",
        "# from timm.data.transforms import _pil_interp\n",
        "# t = []\n",
        "# if True:#config.TEST.CROP:\n",
        "#     size = int((256 / 224) * imageSizePx)\n",
        "#     t.append(\n",
        "#         transforms.Resize(size, interpolation=_pil_interp('bicubic')),\n",
        "#         # to maintain same ratio w.r.t. 224 images\n",
        "#     )\n",
        "#     t.append(transforms.CenterCrop(imageSizePx))\n",
        "# else:\n",
        "#     t.append(\n",
        "#         transforms.Resize((imageSizePx, imageSizePx),\n",
        "#                           interpolation=_pil_interp('bicubic'))\n",
        "#     )\n",
        "\n",
        "# t.append(transforms.ToTensor())\n",
        "# t.append(transforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD))\n",
        "# OtherTransform = transforms.Compose(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {
        "id": "VkBwfUFl3RYs"
      },
      "outputs": [],
      "source": [
        "DR_VAL_DATA = torchvision.datasets.ImageFolder(r'E:\\Fundus images\\G30-G32_Other degenerative_diseases_of_nervous_system\\val',  transform = NORMtransform,)\n",
        "data_loader = torch.utils.data.DataLoader(DR_VAL_DATA,\n",
        "                                          batch_size=batchSize,\n",
        "                                          shuffle=False,\n",
        "                                          # transform = NORMtransform,\n",
        "                                          # num_workers=args.nThreads\n",
        "                                          )\n",
        "\n",
        "# torchvision.datasets.ImageFolder(root: str, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, loader: Callable[[str], Any] = <function default_loader>, is_valid_file: Optional[Callable[[str], bool]] = None)\n",
        "# root (string) – Root directory path.\n",
        "\n",
        "# transform (callable, optional) – A function/transform that takes in an PIL image and returns a transformed version. E.g, transforms.RandomCrop\n",
        "\n",
        "# target_transform (callable, optional) – A function/transform that takes in the target and transforms it.\n",
        "\n",
        "# loader (callable, optional) – A function to load an image given its path.\n",
        "\n",
        "# is_valid_file – A function that takes path of an Image file and check if the file is a valid file (used to check of corrupt files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1gUzogp2zVT"
      },
      "source": [
        "#Model Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJ3hsrZf_ImG",
        "outputId": "d625ebd7-2108-4771-8212-6b9316de02a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: timm in c:\\programdata\\anaconda3\\envs\\swinex\\lib\\site-packages (0.4.12)\n",
            "Requirement already satisfied: torchvision in c:\\programdata\\anaconda3\\envs\\swinex\\lib\\site-packages (from timm) (0.12.0)\n",
            "Requirement already satisfied: torch>=1.4 in c:\\programdata\\anaconda3\\envs\\swinex\\lib\\site-packages (from timm) (1.11.0)\n",
            "Requirement already satisfied: typing_extensions in c:\\programdata\\anaconda3\\envs\\swinex\\lib\\site-packages (from torch>=1.4->timm) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\envs\\swinex\\lib\\site-packages (from torchvision->timm) (1.20.3)\n",
            "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\envs\\swinex\\lib\\site-packages (from torchvision->timm) (2.26.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\programdata\\anaconda3\\envs\\swinex\\lib\\site-packages (from torchvision->timm) (8.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\envs\\swinex\\lib\\site-packages (from requests->torchvision->timm) (3.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\swinex\\lib\\site-packages (from requests->torchvision->timm) (1.26.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\envs\\swinex\\lib\\site-packages (from requests->torchvision->timm) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\swinex\\lib\\site-packages (from requests->torchvision->timm) (2021.10.8)\n"
          ]
        }
      ],
      "source": [
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "81C6qBps_HVv"
      },
      "outputs": [],
      "source": [
        "import timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "tf3yvgQo2xjy"
      },
      "outputs": [],
      "source": [
        "# --------------------------------------------------------\n",
        "# Swin Transformer\n",
        "# Copyright (c) 2021 Microsoft\n",
        "# Licensed under The MIT License [see LICENSE for details]\n",
        "# Written by Ze Liu, Yutong Lin, Yixuan Wei\n",
        "# --------------------------------------------------------\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.checkpoint as checkpoint\n",
        "import numpy as np\n",
        "from timm.models.layers import DropPath, to_2tuple, trunc_normal_\n",
        "\n",
        "\n",
        "class Mlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
        "        super().__init__()\n",
        "        out_features = out_features or in_features\n",
        "        hidden_features = hidden_features or in_features\n",
        "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
        "        self.act = act_layer()\n",
        "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.drop(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def window_partition(x, window_size):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        x: (B, H, W, C)\n",
        "        window_size (int): window size\n",
        "    Returns:\n",
        "        windows: (num_windows*B, window_size, window_size, C)\n",
        "    \"\"\"\n",
        "    B, H, W, C = x.shape\n",
        "    x = x.view(B, H // window_size, window_size, W // window_size, window_size, C)\n",
        "    windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, window_size, window_size, C)\n",
        "    return windows\n",
        "\n",
        "\n",
        "def window_reverse(windows, window_size, H, W):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        windows: (num_windows*B, window_size, window_size, C)\n",
        "        window_size (int): Window size\n",
        "        H (int): Height of image\n",
        "        W (int): Width of image\n",
        "    Returns:\n",
        "        x: (B, H, W, C)\n",
        "    \"\"\"\n",
        "    B = int(windows.shape[0] / (H * W / window_size / window_size))\n",
        "    x = windows.view(B, H // window_size, W // window_size, window_size, window_size, -1)\n",
        "    x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(B, H, W, -1)\n",
        "    return x\n",
        "\n",
        "\n",
        "class WindowAttention(nn.Module):\n",
        "    r\"\"\" Window based multi-head self attention (W-MSA) module with relative position bias.\n",
        "    It supports both of shifted and non-shifted window.\n",
        "    Args:\n",
        "        dim (int): Number of input channels.\n",
        "        window_size (tuple[int]): The height and width of the window.\n",
        "        num_heads (int): Number of attention heads.\n",
        "        qkv_bias (bool, optional):  If True, add a learnable bias to query, key, value. Default: True\n",
        "        qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set\n",
        "        attn_drop (float, optional): Dropout ratio of attention weight. Default: 0.0\n",
        "        proj_drop (float, optional): Dropout ratio of output. Default: 0.0\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dim, window_size, num_heads, qkv_bias=True, qk_scale=None, attn_drop=0., proj_drop=0.):\n",
        "\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.window_size = window_size  # Wh, Ww\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = qk_scale or head_dim ** -0.5\n",
        "\n",
        "        # define a parameter table of relative position bias\n",
        "        self.relative_position_bias_table = nn.Parameter(\n",
        "            torch.zeros((2 * window_size[0] - 1) * (2 * window_size[1] - 1), num_heads))  # 2*Wh-1 * 2*Ww-1, nH\n",
        "\n",
        "        # get pair-wise relative position index for each token inside the window\n",
        "        coords_h = torch.arange(self.window_size[0])\n",
        "        coords_w = torch.arange(self.window_size[1])\n",
        "        coords = torch.stack(torch.meshgrid([coords_h, coords_w]))  # 2, Wh, Ww\n",
        "        coords_flatten = torch.flatten(coords, 1)  # 2, Wh*Ww\n",
        "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]  # 2, Wh*Ww, Wh*Ww\n",
        "        relative_coords = relative_coords.permute(1, 2, 0).contiguous()  # Wh*Ww, Wh*Ww, 2\n",
        "        relative_coords[:, :, 0] += self.window_size[0] - 1  # shift to start from 0\n",
        "        relative_coords[:, :, 1] += self.window_size[1] - 1\n",
        "        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n",
        "        relative_position_index = relative_coords.sum(-1)  # Wh*Ww, Wh*Ww\n",
        "        self.register_buffer(\"relative_position_index\", relative_position_index)\n",
        "\n",
        "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_drop)\n",
        "\n",
        "        trunc_normal_(self.relative_position_bias_table, std=.02)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: input features with shape of (num_windows*B, N, C)\n",
        "            mask: (0/-inf) mask with shape of (num_windows, Wh*Ww, Wh*Ww) or None\n",
        "        \"\"\"\n",
        "        B_, N, C = x.shape\n",
        "        qkv = self.qkv(x).reshape(B_, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]  # make torchscript happy (cannot use tensor as tuple)\n",
        "\n",
        "        q = q * self.scale\n",
        "        attn = (q @ k.transpose(-2, -1))\n",
        "\n",
        "        relative_position_bias = self.relative_position_bias_table[self.relative_position_index.view(-1)].view(\n",
        "            self.window_size[0] * self.window_size[1], self.window_size[0] * self.window_size[1], -1)  # Wh*Ww,Wh*Ww,nH\n",
        "        relative_position_bias = relative_position_bias.permute(2, 0, 1).contiguous()  # nH, Wh*Ww, Wh*Ww\n",
        "        attn = attn + relative_position_bias.unsqueeze(0)\n",
        "\n",
        "        if mask is not None:\n",
        "            nW = mask.shape[0]\n",
        "            attn = attn.view(B_ // nW, nW, self.num_heads, N, N) + mask.unsqueeze(1).unsqueeze(0)\n",
        "            attn = attn.view(-1, self.num_heads, N, N)\n",
        "            attn = self.softmax(attn)\n",
        "        else:\n",
        "            attn = self.softmax(attn)\n",
        "\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B_, N, C)\n",
        "        x = self.proj(x)\n",
        "        x = self.proj_drop(x)\n",
        "        return x\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        return f'dim={self.dim}, window_size={self.window_size}, num_heads={self.num_heads}'\n",
        "\n",
        "    def flops(self, N):\n",
        "        # calculate flops for 1 window with token length of N\n",
        "        flops = 0\n",
        "        # qkv = self.qkv(x)\n",
        "        flops += N * self.dim * 3 * self.dim\n",
        "        # attn = (q @ k.transpose(-2, -1))\n",
        "        flops += self.num_heads * N * (self.dim // self.num_heads) * N\n",
        "        #  x = (attn @ v)\n",
        "        flops += self.num_heads * N * N * (self.dim // self.num_heads)\n",
        "        # x = self.proj(x)\n",
        "        flops += N * self.dim * self.dim\n",
        "        return flops\n",
        "\n",
        "\n",
        "class SwinTransformerBlock(nn.Module):\n",
        "    r\"\"\" Swin Transformer Block.\n",
        "    Args:\n",
        "        dim (int): Number of input channels.\n",
        "        input_resolution (tuple[int]): Input resulotion.\n",
        "        num_heads (int): Number of attention heads.\n",
        "        window_size (int): Window size.\n",
        "        shift_size (int): Shift size for SW-MSA.\n",
        "        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.\n",
        "        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True\n",
        "        qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set.\n",
        "        drop (float, optional): Dropout rate. Default: 0.0\n",
        "        attn_drop (float, optional): Attention dropout rate. Default: 0.0\n",
        "        drop_path (float, optional): Stochastic depth rate. Default: 0.0\n",
        "        act_layer (nn.Module, optional): Activation layer. Default: nn.GELU\n",
        "        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dim, input_resolution, num_heads, window_size=7, shift_size=0,\n",
        "                 mlp_ratio=4., qkv_bias=True, qk_scale=None, drop=0., attn_drop=0., drop_path=0.,\n",
        "                 act_layer=nn.GELU, norm_layer=nn.LayerNorm):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.input_resolution = input_resolution\n",
        "        self.num_heads = num_heads\n",
        "        self.window_size = window_size\n",
        "        self.shift_size = shift_size\n",
        "        self.mlp_ratio = mlp_ratio\n",
        "        if min(self.input_resolution) <= self.window_size:\n",
        "            # if window size is larger than input resolution, we don't partition windows\n",
        "            self.shift_size = 0\n",
        "            self.window_size = min(self.input_resolution)\n",
        "        assert 0 <= self.shift_size < self.window_size, \"shift_size must in 0-window_size\"\n",
        "\n",
        "        self.norm1 = norm_layer(dim)\n",
        "        self.attn = WindowAttention(\n",
        "            dim, window_size=to_2tuple(self.window_size), num_heads=num_heads,\n",
        "            qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n",
        "\n",
        "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
        "        self.norm2 = norm_layer(dim)\n",
        "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
        "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
        "\n",
        "        if self.shift_size > 0:\n",
        "            # calculate attention mask for SW-MSA\n",
        "            H, W = self.input_resolution\n",
        "            img_mask = torch.zeros((1, H, W, 1))  # 1 H W 1\n",
        "            h_slices = (slice(0, -self.window_size),\n",
        "                        slice(-self.window_size, -self.shift_size),\n",
        "                        slice(-self.shift_size, None))\n",
        "            w_slices = (slice(0, -self.window_size),\n",
        "                        slice(-self.window_size, -self.shift_size),\n",
        "                        slice(-self.shift_size, None))\n",
        "            cnt = 0\n",
        "            for h in h_slices:\n",
        "                for w in w_slices:\n",
        "                    img_mask[:, h, w, :] = cnt\n",
        "                    cnt += 1\n",
        "\n",
        "            mask_windows = window_partition(img_mask, self.window_size)  # nW, window_size, window_size, 1\n",
        "            mask_windows = mask_windows.view(-1, self.window_size * self.window_size)\n",
        "            attn_mask = mask_windows.unsqueeze(1) - mask_windows.unsqueeze(2)\n",
        "            attn_mask = attn_mask.masked_fill(attn_mask != 0, float(-100.0)).masked_fill(attn_mask == 0, float(0.0))\n",
        "        else:\n",
        "            attn_mask = None\n",
        "\n",
        "        self.register_buffer(\"attn_mask\", attn_mask)\n",
        "\n",
        "    def forward(self, x):\n",
        "        H, W = self.input_resolution\n",
        "        B, L, C = x.shape\n",
        "        assert L == H * W, \"input feature has wrong size\"\n",
        "\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = x.view(B, H, W, C)\n",
        "\n",
        "        # cyclic shift\n",
        "        if self.shift_size > 0:\n",
        "            shifted_x = torch.roll(x, shifts=(-self.shift_size, -self.shift_size), dims=(1, 2))\n",
        "        else:\n",
        "            shifted_x = x\n",
        "\n",
        "        # partition windows\n",
        "        x_windows = window_partition(shifted_x, self.window_size)  # nW*B, window_size, window_size, C\n",
        "        x_windows = x_windows.view(-1, self.window_size * self.window_size, C)  # nW*B, window_size*window_size, C\n",
        "\n",
        "        # W-MSA/SW-MSA\n",
        "        attn_windows = self.attn(x_windows, mask=self.attn_mask)  # nW*B, window_size*window_size, C\n",
        "\n",
        "        # merge windows\n",
        "        attn_windows = attn_windows.view(-1, self.window_size, self.window_size, C)\n",
        "        shifted_x = window_reverse(attn_windows, self.window_size, H, W)  # B H' W' C\n",
        "\n",
        "        # reverse cyclic shift\n",
        "        if self.shift_size > 0:\n",
        "            x = torch.roll(shifted_x, shifts=(self.shift_size, self.shift_size), dims=(1, 2))\n",
        "        else:\n",
        "            x = shifted_x\n",
        "        x = x.view(B, H * W, C)\n",
        "\n",
        "        # FFN\n",
        "        x = shortcut + self.drop_path(x)\n",
        "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
        "\n",
        "        return x\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        return f\"dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, \" \\\n",
        "               f\"window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}\"\n",
        "\n",
        "    def flops(self):\n",
        "        flops = 0\n",
        "        H, W = self.input_resolution\n",
        "        # norm1\n",
        "        flops += self.dim * H * W\n",
        "        # W-MSA/SW-MSA\n",
        "        nW = H * W / self.window_size / self.window_size\n",
        "        flops += nW * self.attn.flops(self.window_size * self.window_size)\n",
        "        # mlp\n",
        "        flops += 2 * H * W * self.dim * self.dim * self.mlp_ratio\n",
        "        # norm2\n",
        "        flops += self.dim * H * W\n",
        "        return flops\n",
        "\n",
        "\n",
        "class PatchMerging(nn.Module):\n",
        "    r\"\"\" Patch Merging Layer.\n",
        "    Args:\n",
        "        input_resolution (tuple[int]): Resolution of input feature.\n",
        "        dim (int): Number of input channels.\n",
        "        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_resolution, dim, norm_layer=nn.LayerNorm):\n",
        "        super().__init__()\n",
        "        self.input_resolution = input_resolution\n",
        "        self.dim = dim\n",
        "        self.reduction = nn.Linear(4 * dim, 2 * dim, bias=False)\n",
        "        self.norm = norm_layer(4 * dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: B, H*W, C\n",
        "        \"\"\"\n",
        "        H, W = self.input_resolution\n",
        "        B, L, C = x.shape\n",
        "        assert L == H * W, \"input feature has wrong size\"\n",
        "        assert H % 2 == 0 and W % 2 == 0, f\"x size ({H}*{W}) are not even.\"\n",
        "\n",
        "        x = x.view(B, H, W, C)\n",
        "\n",
        "        x0 = x[:, 0::2, 0::2, :]  # B H/2 W/2 C\n",
        "        x1 = x[:, 1::2, 0::2, :]  # B H/2 W/2 C\n",
        "        x2 = x[:, 0::2, 1::2, :]  # B H/2 W/2 C\n",
        "        x3 = x[:, 1::2, 1::2, :]  # B H/2 W/2 C\n",
        "        x = torch.cat([x0, x1, x2, x3], -1)  # B H/2 W/2 4*C\n",
        "        x = x.view(B, -1, 4 * C)  # B H/2*W/2 4*C\n",
        "\n",
        "        x = self.norm(x)\n",
        "        x = self.reduction(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        return f\"input_resolution={self.input_resolution}, dim={self.dim}\"\n",
        "\n",
        "    def flops(self):\n",
        "        H, W = self.input_resolution\n",
        "        flops = H * W * self.dim\n",
        "        flops += (H // 2) * (W // 2) * 4 * self.dim * 2 * self.dim\n",
        "        return flops\n",
        "\n",
        "\n",
        "class BasicLayer(nn.Module):\n",
        "    \"\"\" A basic Swin Transformer layer for one stage.\n",
        "    Args:\n",
        "        dim (int): Number of input channels.\n",
        "        input_resolution (tuple[int]): Input resolution.\n",
        "        depth (int): Number of blocks.\n",
        "        num_heads (int): Number of attention heads.\n",
        "        window_size (int): Local window size.\n",
        "        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.\n",
        "        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True\n",
        "        qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set.\n",
        "        drop (float, optional): Dropout rate. Default: 0.0\n",
        "        attn_drop (float, optional): Attention dropout rate. Default: 0.0\n",
        "        drop_path (float | tuple[float], optional): Stochastic depth rate. Default: 0.0\n",
        "        norm_layer (nn.Module, optional): Normalization layer. Default: nn.LayerNorm\n",
        "        downsample (nn.Module | None, optional): Downsample layer at the end of the layer. Default: None\n",
        "        use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dim, input_resolution, depth, num_heads, window_size,\n",
        "                 mlp_ratio=4., qkv_bias=True, qk_scale=None, drop=0., attn_drop=0.,\n",
        "                 drop_path=0., norm_layer=nn.LayerNorm, downsample=None, use_checkpoint=False):\n",
        "\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.input_resolution = input_resolution\n",
        "        self.depth = depth\n",
        "        self.use_checkpoint = use_checkpoint\n",
        "\n",
        "        # build blocks\n",
        "        self.blocks = nn.ModuleList([\n",
        "            SwinTransformerBlock(dim=dim, input_resolution=input_resolution,\n",
        "                                 num_heads=num_heads, window_size=window_size,\n",
        "                                 shift_size=0 if (i % 2 == 0) else window_size // 2,\n",
        "                                 mlp_ratio=mlp_ratio,\n",
        "                                 qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
        "                                 drop=drop, attn_drop=attn_drop,\n",
        "                                 drop_path=drop_path[i] if isinstance(drop_path, list) else drop_path,\n",
        "                                 norm_layer=norm_layer)\n",
        "            for i in range(depth)])\n",
        "\n",
        "        # patch merging layer\n",
        "        if downsample is not None:\n",
        "            self.downsample = downsample(input_resolution, dim=dim, norm_layer=norm_layer)\n",
        "        else:\n",
        "            self.downsample = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        for blk in self.blocks:\n",
        "            if self.use_checkpoint:\n",
        "                x = checkpoint.checkpoint(blk, x)\n",
        "            else:\n",
        "                x = blk(x)\n",
        "        if self.downsample is not None:\n",
        "            x = self.downsample(x)\n",
        "        return x\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        return f\"dim={self.dim}, input_resolution={self.input_resolution}, depth={self.depth}\"\n",
        "\n",
        "    def flops(self):\n",
        "        flops = 0\n",
        "        for blk in self.blocks:\n",
        "            flops += blk.flops()\n",
        "        if self.downsample is not None:\n",
        "            flops += self.downsample.flops()\n",
        "        return flops\n",
        "\n",
        "\n",
        "class PatchEmbed(nn.Module):\n",
        "    r\"\"\" Image to Patch Embedding\n",
        "    Args:\n",
        "        img_size (int): Image size.  Default: 224.\n",
        "        patch_size (int): Patch token size. Default: 4.\n",
        "        in_chans (int): Number of input image channels. Default: 3.\n",
        "        embed_dim (int): Number of linear projection output channels. Default: 96.\n",
        "        norm_layer (nn.Module, optional): Normalization layer. Default: None\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, img_size=224, patch_size=4, in_chans=3, embed_dim=96, norm_layer=None):\n",
        "        super().__init__()\n",
        "        img_size = to_2tuple(img_size)\n",
        "        patch_size = to_2tuple(patch_size)\n",
        "        patches_resolution = [img_size[0] // patch_size[0], img_size[1] // patch_size[1]]\n",
        "        self.img_size = img_size\n",
        "        self.patch_size = patch_size\n",
        "        self.patches_resolution = patches_resolution\n",
        "        self.num_patches = patches_resolution[0] * patches_resolution[1]\n",
        "\n",
        "        self.in_chans = in_chans\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "        if norm_layer is not None:\n",
        "            self.norm = norm_layer(embed_dim)\n",
        "        else:\n",
        "            self.norm = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "        # FIXME look at relaxing size constraints\n",
        "        assert H == self.img_size[0] and W == self.img_size[1], \\\n",
        "            f\"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\"\n",
        "        x = self.proj(x).flatten(2).transpose(1, 2)  # B Ph*Pw C\n",
        "        if self.norm is not None:\n",
        "            x = self.norm(x)\n",
        "        return x\n",
        "\n",
        "    def flops(self):\n",
        "        Ho, Wo = self.patches_resolution\n",
        "        flops = Ho * Wo * self.embed_dim * self.in_chans * (self.patch_size[0] * self.patch_size[1])\n",
        "        if self.norm is not None:\n",
        "            flops += Ho * Wo * self.embed_dim\n",
        "        return flops\n",
        "\n",
        "\n",
        "class SwinTransformer(nn.Module):\n",
        "    r\"\"\" Swin Transformer\n",
        "        A PyTorch impl of : `Swin Transformer: Hierarchical Vision Transformer using Shifted Windows`  -\n",
        "          https://arxiv.org/pdf/2103.14030\n",
        "    Args:\n",
        "        img_size (int | tuple(int)): Input image size. Default 224\n",
        "        patch_size (int | tuple(int)): Patch size. Default: 4\n",
        "        in_chans (int): Number of input image channels. Default: 3\n",
        "        num_classes (int): Number of classes for classification head. Default: 1000\n",
        "        embed_dim (int): Patch embedding dimension. Default: 96\n",
        "        depths (tuple(int)): Depth of each Swin Transformer layer.\n",
        "        num_heads (tuple(int)): Number of attention heads in different layers.\n",
        "        window_size (int): Window size. Default: 7\n",
        "        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim. Default: 4\n",
        "        qkv_bias (bool): If True, add a learnable bias to query, key, value. Default: True\n",
        "        qk_scale (float): Override default qk scale of head_dim ** -0.5 if set. Default: None\n",
        "        drop_rate (float): Dropout rate. Default: 0\n",
        "        attn_drop_rate (float): Attention dropout rate. Default: 0\n",
        "        drop_path_rate (float): Stochastic depth rate. Default: 0.1\n",
        "        norm_layer (nn.Module): Normalization layer. Default: nn.LayerNorm.\n",
        "        ape (bool): If True, add absolute position embedding to the patch embedding. Default: False\n",
        "        patch_norm (bool): If True, add normalization after patch embedding. Default: True\n",
        "        use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, img_size=224, patch_size=4, in_chans=3, num_classes=1000,\n",
        "                 embed_dim=96, depths=[2, 2, 6, 2], num_heads=[3, 6, 12, 24],\n",
        "                 window_size=7, mlp_ratio=4., qkv_bias=True, qk_scale=None,\n",
        "                 drop_rate=0., attn_drop_rate=0., drop_path_rate=0.1,\n",
        "                 norm_layer=nn.LayerNorm, ape=False, patch_norm=True,\n",
        "                 use_checkpoint=False, **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "        self.num_layers = len(depths)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.ape = ape\n",
        "        self.patch_norm = patch_norm\n",
        "        self.num_features = int(embed_dim * 2 ** (self.num_layers - 1))\n",
        "        self.mlp_ratio = mlp_ratio\n",
        "\n",
        "        # split image into non-overlapping patches\n",
        "        self.patch_embed = PatchEmbed(\n",
        "            img_size=img_size, patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim,\n",
        "            norm_layer=norm_layer if self.patch_norm else None)\n",
        "        num_patches = self.patch_embed.num_patches\n",
        "        patches_resolution = self.patch_embed.patches_resolution\n",
        "        self.patches_resolution = patches_resolution\n",
        "\n",
        "        # absolute position embedding\n",
        "        if self.ape:\n",
        "            self.absolute_pos_embed = nn.Parameter(torch.zeros(1, num_patches, embed_dim))\n",
        "            trunc_normal_(self.absolute_pos_embed, std=.02)\n",
        "\n",
        "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
        "\n",
        "        # stochastic depth\n",
        "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]  # stochastic depth decay rule\n",
        "\n",
        "        # build layers\n",
        "        self.layers = nn.ModuleList()\n",
        "        for i_layer in range(self.num_layers):\n",
        "            layer = BasicLayer(dim=int(embed_dim * 2 ** i_layer),\n",
        "                               input_resolution=(patches_resolution[0] // (2 ** i_layer),\n",
        "                                                 patches_resolution[1] // (2 ** i_layer)),\n",
        "                               depth=depths[i_layer],\n",
        "                               num_heads=num_heads[i_layer],\n",
        "                               window_size=window_size,\n",
        "                               mlp_ratio=self.mlp_ratio,\n",
        "                               qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
        "                               drop=drop_rate, attn_drop=attn_drop_rate,\n",
        "                               drop_path=dpr[sum(depths[:i_layer]):sum(depths[:i_layer + 1])],\n",
        "                               norm_layer=norm_layer,\n",
        "                               downsample=PatchMerging if (i_layer < self.num_layers - 1) else None,\n",
        "                               use_checkpoint=use_checkpoint)\n",
        "            self.layers.append(layer)\n",
        "\n",
        "        self.norm = norm_layer(self.num_features)\n",
        "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.head = nn.Linear(self.num_features, num_classes) if num_classes > 0 else nn.Identity()\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            trunc_normal_(m.weight, std=.02)\n",
        "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.LayerNorm):\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "            nn.init.constant_(m.weight, 1.0)\n",
        "\n",
        "    @torch.jit.ignore\n",
        "    def no_weight_decay(self):\n",
        "        return {'absolute_pos_embed'}\n",
        "\n",
        "    @torch.jit.ignore\n",
        "    def no_weight_decay_keywords(self):\n",
        "        return {'relative_position_bias_table'}\n",
        "\n",
        "    def forward_features(self, x):\n",
        "        x = self.patch_embed(x)\n",
        "        if self.ape:\n",
        "            x = x + self.absolute_pos_embed\n",
        "        x = self.pos_drop(x)\n",
        "\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "\n",
        "        x = self.norm(x)  # B L C\n",
        "        x = self.avgpool(x.transpose(1, 2))  # B C 1\n",
        "        x = torch.flatten(x, 1)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.forward_features(x)\n",
        "        x = self.head(x)\n",
        "        return x\n",
        "\n",
        "    def flops(self):\n",
        "        flops = 0\n",
        "        flops += self.patch_embed.flops()\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            flops += layer.flops()\n",
        "        flops += self.num_features * self.patches_resolution[0] * self.patches_resolution[1] // (2 ** self.num_layers)\n",
        "        flops += self.num_features * self.num_classes\n",
        "        return flops\n",
        "\n",
        "def swin_t_patch4_224_diagnosis(image_size=224, pretrained=False, pretrainPath='', classNumber=2, windowSize=7, **kwargs):\n",
        "    model = SwinTransformer(img_size=image_size, num_classes=classNumber, window_size=windowSize)\n",
        "    if pretrained:\n",
        "        checkpoint = torch.load(pretrainPath, map_location='cpu')\n",
        "        state_dict = checkpoint['model']\n",
        "\n",
        "        msg = model.load_state_dict(state_dict, strict=False)\n",
        "        print(msg)\n",
        "\n",
        "        print(f\"=> loaded successfully {pretrainPath}\")\n",
        "\n",
        "        del checkpoint\n",
        "        torch.cuda.empty_cache()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdWtlzXY22rw"
      },
      "source": [
        "#Model Init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_NyNct4Baqp",
        "outputId": "fa9f630f-73ef-4bba-ef4f-b2283d1fda87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: yacs in c:\\programdata\\anaconda3\\envs\\swinex\\lib\\site-packages (0.1.8)\n",
            "Requirement already satisfied: PyYAML in c:\\programdata\\anaconda3\\envs\\swinex\\lib\\site-packages (from yacs) (6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install yacs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdXIV5p82yWY",
        "outputId": "c69ae3e3-5132-4ee6-ba66-03005af20eba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<All keys matched successfully>\n",
            "=> loaded successfully E:\\models\\diagnosis\\G30-G32_Other_degenerative_diseases_of_nervous_system\\swin_tiny_patch4_window7_224\\ImageNetMoBy224\\ckpt_epoch_4.pth\n"
          ]
        }
      ],
      "source": [
        "import yacs\n",
        "\n",
        "#from checkpoint\n",
        "pretrainedPath = pretrainedPath\n",
        "model = swin_t_patch4_224_diagnosis(image_size=imageSizePx, pretrained=True, pretrainPath=pretrainedPath, classNumber=numClasses, windowSize=window_Size)#swin_t_patch4_224(pretrained=True)#timm.create_model('swin_base_patch4_window7_224', pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# if args.use_cuda:\n",
        "model = model.to(device)#.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFG4mRsi24hl"
      },
      "source": [
        "#Calc Metrics on val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtFXwviDHsgF"
      },
      "source": [
        "##Setup Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQ8SU5DOoLgm",
        "outputId": "fdb5957c-f82c-4957-b21c-64be632740cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.8.2-py3-none-any.whl (409 kB)\n",
            "Requirement already satisfied: torch>=1.3.1 in c:\\programdata\\anaconda3\\envs\\swinex\\lib\\site-packages (from torchmetrics) (1.11.0)\n",
            "Collecting pyDeprecate==0.3.*\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: numpy>=1.17.2 in c:\\programdata\\anaconda3\\envs\\swinex\\lib\\site-packages (from torchmetrics) (1.20.3)\n",
            "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\envs\\swinex\\lib\\site-packages (from torchmetrics) (21.0)\n",
            "Requirement already satisfied: typing_extensions in c:\\programdata\\anaconda3\\envs\\swinex\\lib\\site-packages (from torch>=1.3.1->torchmetrics) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\envs\\swinex\\lib\\site-packages (from packaging->torchmetrics) (3.0.4)\n",
            "Installing collected packages: pyDeprecate, torchmetrics\n",
            "Successfully installed pyDeprecate-0.3.2 torchmetrics-0.8.2\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KS-7MqPpJTv",
        "outputId": "70a945eb-bbd9-4571-b6ee-086612ef9fb2"
      },
      "outputs": [],
      "source": [
        "# import library\n",
        "import torchmetrics\n",
        "\n",
        "# from torchmetrics.functional import auc\n",
        "from torchmetrics import AUROC\n",
        "from torchmetrics import ROC\n",
        "from torchmetrics import Specificity\n",
        "\n",
        "from torchmetrics.classification import StatScores\n",
        "\n",
        "from torchmetrics import Precision\n",
        "from torchmetrics import Recall\n",
        "from torchmetrics import Accuracy\n",
        "from torchmetrics import F1Score\n",
        "# from torchmetrics.functional import precision_recall\n",
        "from torchmetrics import CohenKappa\n",
        "from torchmetrics import PrecisionRecallCurve\n",
        "from torchmetrics import ConfusionMatrix\n",
        "\n",
        "#-------------------------------------------------------------Params\n",
        "NumClasses = realClassNumber#5#1000#realClassNumber#1000#5\n",
        "\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------# initialize metrics\n",
        "if False:#binaryClassification: #determine threshold then other metrics\n",
        "  roc_Metric = ROC(pos_label=1)\n",
        "  # fpr, tpr, thresholds = roc(pred, target)\n",
        "  pr_curve_Metric = PrecisionRecallCurve(pos_label=1)\n",
        "  # precision, recall, thresholds = pr_curve(pred, target)\n",
        "  #------------------------------------------------------\n",
        "  auroc_Metric = AUROC(pos_label=1)\n",
        "  # auroc(preds, target)\n",
        "  stat_scores_Metric = StatScores(threshold=0.5, reduce='micro')\n",
        "  # stat_scores(preds, target)\n",
        "  precision_Metric = Precision(threshold=0.5, average='micro') #Default value of 0.5 corresponds to input being probabilities.\n",
        "  # # precision(preds, target)\n",
        "  recall_Metric = Recall(threshold=0.5, average='micro')\n",
        "  # # recall(preds, target)\n",
        "  # precision_recall(preds, target, average='macro', num_classes=NumClasses)#threshold=0.5\n",
        "  f1_Metric = F1Score(threshold=0.5, average='micro')#threshold=0.5 \n",
        "  # f1(preds, target)\n",
        "  specificity_Metric = Specificity(threshold=0.5, average='micro')\n",
        "  # specificity = Specificity(average='micro')\n",
        "  # specificity(preds, target)\n",
        "  accuracy_Metric = Accuracy(threshold=0.5, average='micro')#threshold=0.5\n",
        "  # accuracy(preds, target)\n",
        "  cohenkappa_Metric = CohenKappa(num_classes=NumClasses, threshold=0.5)#threshold=0.5\n",
        "  # cohenkappa(preds, target)\n",
        "  confmat = ConfusionMatrix(num_classes=NumClasses, threshold=0.5)\n",
        "  # confmat(preds, target)\n",
        "\n",
        "  BinaryMetricsThresh = {\n",
        "    'roc': roc_Metric,\n",
        "    'pr_curve': pr_curve_Metric,\n",
        "  }\n",
        "  BinaryMetrics = {\n",
        "    'auroc': auroc_Metric,\n",
        "    'stat_scores': stat_scores_Metric,\n",
        "    'precision': precision_Metric,\n",
        "    'recall': recall_Metric,\n",
        "    'f1': f1_Metric,\n",
        "    'specificity': specificity_Metric,\n",
        "    'accuracy': accuracy_Metric,\n",
        "    'cohenkappa': cohenkappa_Metric,\n",
        "    'confmat': confmat,\n",
        "  }\n",
        "\n",
        "  for key, metric in BinaryMetricsThresh.items():\n",
        "    metric.to(device)\n",
        "  for key, metric in BinaryMetrics.items():\n",
        "    metric.to(device)\n",
        "else:\n",
        "  auroc_Metric = AUROC(num_classes=NumClasses)\n",
        "  # stat_scores_Metric = StatScores(num_classes=NumClasses, reduce='macro')#reduce='micro'\n",
        "  precision_Metric = Precision(num_classes=NumClasses, average='macro') #Default value of 0.5 corresponds to input being probabilities.\n",
        "  recall_Metric = Recall(num_classes=NumClasses, average='macro')\n",
        "  f1_Metric = F1Score(num_classes=NumClasses, average='macro')#threshold=0.5 \n",
        "  accuracy_Metric = Accuracy(num_classes=NumClasses, average='macro')#threshold=0.5\n",
        "  cohenkappa_Metric = CohenKappa(num_classes=NumClasses)#threshold=0.5\n",
        "  confmat = ConfusionMatrix(num_classes=NumClasses)\n",
        "  # confmat(preds, target)\n",
        "  MultiClassMetrics = {\n",
        "      \"Area Under ROC Curve\" : auroc_Metric,\n",
        "      \"Precision\" : precision_Metric,\n",
        "      \"Recall\" : recall_Metric,\n",
        "      \"F1 Score\" : f1_Metric,\n",
        "      \"Accuracy\" : accuracy_Metric,\n",
        "      \"Cohen kappa coefficient\" : cohenkappa_Metric,\n",
        "      \"Confusion Matrix\" : confmat,\n",
        "  }\n",
        "  #[auroc_Metric, precision_Metric, recall_Metric, f1_Metric, accuracy_Metric, cohenkappa_Metric, confmat]#stat_scores_Metric, \n",
        "\n",
        "  # for metric in MultiClassMetrics:\n",
        "  for key, metric in MultiClassMetrics.items():\n",
        "    metric.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzJ4BMfC1TPS"
      },
      "source": [
        "#Binary Classification metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jUdCY-PZR2z",
        "outputId": "4f3afe22-e980-4ee8-f961-ece02b4b172a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/516 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Detected input to `multiclass` but you did not provide `num_classes` argument",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17684/4178579804.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[1;31m# metric on current batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mBinaryMetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[0mmetric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;31m# metric on all batches using custom accumulation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\swinEx\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\swinEx\\lib\\site-packages\\torchmetrics\\metric.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_cache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[1;31m# restore context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\swinEx\\lib\\site-packages\\torchmetrics\\metric.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    438\u001b[0m                 \u001b[0mshould_unsync\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_unsync\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m             ):\n\u001b[1;32m--> 440\u001b[1;33m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_computed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_squeeze_if_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\swinEx\\lib\\site-packages\\torchmetrics\\classification\\auroc.py\u001b[0m in \u001b[0;36mcompute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdim_zero_cat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdim_zero_cat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         return _auroc_compute(\n\u001b[0m\u001b[0;32m    176\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m             \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\swinEx\\lib\\site-packages\\torchmetrics\\functional\\classification\\auroc.py\u001b[0m in \u001b[0;36m_auroc_compute\u001b[1;34m(preds, target, mode, num_classes, pos_label, average, max_fpr, sample_weights)\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mDataType\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBINARY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Detected input to `multiclass` but you did not provide `num_classes` argument\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mAverageMethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWEIGHTED\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                 \u001b[1;31m# If one or more classes has 0 observations, we should exclude them, as its weight will be 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: Detected input to `multiclass` but you did not provide `num_classes` argument"
          ]
        }
      ],
      "source": [
        "# #Find best thresh - for binary only....\n",
        "# import time\n",
        "# import datetime\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# start_time = time.time()\n",
        "# for idx, (samples_1, targets) in enumerate(tqdm(data_loader)):\n",
        "#   input_tensor_cuda=samples_1.cuda()\n",
        "#   output = model(input_tensor_cuda)\n",
        "\n",
        "#   preds = output.detach()\n",
        "#   target = targets.cuda()\n",
        "\n",
        "#   preds = preds[: , :realClassNumber]#remove extra classes ------------------------- :(\n",
        "\n",
        "#   # fpr, tpr, thresholds = roc_Metric(preds, target)\n",
        "#   # precision, recall, thresholds = pr_curve_Metric(preds, target)\n",
        "\n",
        "# # metric on all batches\n",
        "# roc = roc_Metric.compute()\n",
        "# pr_curve = pr_curve_Metric.compute()\n",
        "# print(f\"\\nroc on all data: {roc}\\n pr curve on all data: {pr_curve}\")\n",
        "\n",
        "# # Reseting internal state such that metric ready for new data\n",
        "# roc_Metric.reset()\n",
        "# pr_curve_Metric.reset()\n",
        "\n",
        "# total_time = time.time() - start_time\n",
        "# total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "# print('\\nTesting time {}'.format(total_time_str))\n",
        "\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------Run batches\n",
        "import time\n",
        "import datetime\n",
        "from tqdm import tqdm\n",
        "\n",
        "import itertools#for testing limit size\n",
        "# slicedDataloader = itertools.islice(data_loader, 1000)\n",
        "\n",
        "# batch = next(iter(dataloader_train))\n",
        "\n",
        "start_time = time.time()\n",
        "for idx, (samples_1, targets) in enumerate(tqdm(data_loader)):\n",
        "  input_tensor_cuda=samples_1.to(device)#.cuda()\n",
        "  output = model(input_tensor_cuda)\n",
        "\n",
        "  preds = output.detach()\n",
        "  target = targets.to(device)\n",
        "  preds = preds[: , :realClassNumber]#remove extra classes ------------------------- (also adjust classes given to metrics to only 5)\n",
        "\n",
        "  # metric on current batch\n",
        "  for key, metric in BinaryMetrics.items():\n",
        "    metric(preds, target)\n",
        "\n",
        "# metric on all batches using custom accumulation\n",
        "metricsValues = {key:metric.compute() for key, metric in BinaryMetrics.items()}\n",
        "\n",
        "print(f\"\\nMetrics on all data: \")\n",
        "# for metricsResult in metricsList:\n",
        "for key, metric in metricsValues.items():#Print results\n",
        "  print(f\"{key}: {metric}\")\n",
        "\n",
        "# Reseting internal state such that metric ready for new data\n",
        "for key, metric in BinaryMetrics.items():\n",
        "  metric.reset()\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "print('Testing time {}'.format(total_time_str))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfhX9ZT2h--c",
        "outputId": "b1b16657-6c45-4b42-fef5-93868aa78fd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[array([ 0.000,  0.000,  0.000, ...,  1.000,  1.000,  1.000], dtype=float32), array([ 0.000,  0.000,  0.000, ...,  1.000,  1.000,  1.000], dtype=float32), array([ 0.000,  0.000,  0.000, ...,  1.000,  1.000,  1.000], dtype=float32), array([ 0.000,  0.000,  0.000, ...,  1.000,  1.000,  1.000], dtype=float32), array([ 0.000,  0.000,  0.000, ...,  1.000,  1.000,  1.000], dtype=float32)]\n",
            "[array([ 0.000,  0.000,  0.000, ...,  1.000,  1.000,  1.000], dtype=float32), array([ 0.000,  0.001,  0.002, ...,  1.000,  1.000,  1.000], dtype=float32), array([ 0.000,  0.000,  0.001, ...,  1.000,  1.000,  1.000], dtype=float32), array([ 0.000,  0.002,  0.004, ...,  1.000,  1.000,  1.000], dtype=float32), array([ 0.000,  0.002,  0.005, ...,  1.000,  1.000,  1.000], dtype=float32)]\n",
            "[array([ 8.336,  7.336,  7.332, ...,  2.571,  2.569,  2.538], dtype=float32), array([ 7.834,  6.834,  6.808, ...,  0.786,  0.720,  0.704], dtype=float32), array([ 8.453,  7.453,  7.159, ...,  1.489,  1.331,  1.242], dtype=float32), array([ 9.021,  8.021,  7.939, ..., -0.639, -0.652, -0.994], dtype=float32), array([ 8.482,  7.482,  7.419, ..., -1.217, -1.232, -1.319], dtype=float32)]\n",
            "\n",
            "\n",
            "[array([ 0.736,  0.736,  0.736, ...,  1.000,  1.000,  1.000], dtype=float32), array([ 0.075,  0.074,  0.074, ...,  1.000,  1.000,  1.000], dtype=float32), array([ 0.158,  0.158,  0.158, ...,  1.000,  1.000,  1.000], dtype=float32), array([ 0.031,  0.031,  0.031, ...,  1.000,  1.000,  1.000], dtype=float32), array([ 0.032,  0.032,  0.032, ...,  1.000,  1.000,  1.000], dtype=float32)]\n",
            "[array([ 1.000,  1.000,  1.000, ...,  0.000,  0.000,  0.000], dtype=float32), array([ 1.000,  0.999,  0.999, ...,  0.002,  0.001,  0.000], dtype=float32), array([ 1.000,  1.000,  1.000, ...,  0.001,  0.000,  0.000], dtype=float32), array([ 1.000,  0.998,  0.998, ...,  0.004,  0.002,  0.000], dtype=float32), array([ 1.000,  0.998,  0.998, ...,  0.005,  0.002,  0.000], dtype=float32)]\n",
            "[array([ 3.103,  3.103,  3.103, ...,  7.321,  7.332,  7.336], dtype=float32), array([ 1.748,  1.749,  1.750, ...,  6.778,  6.808,  6.834], dtype=float32), array([ 2.359,  2.359,  2.359, ...,  7.128,  7.159,  7.453], dtype=float32), array([ 0.012,  0.012,  0.012, ...,  7.901,  7.939,  8.021], dtype=float32), array([-0.085, -0.085, -0.085, ...,  7.408,  7.419,  7.482], dtype=float32)]\n"
          ]
        }
      ],
      "source": [
        "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
        "# print(roc)\n",
        "fpr, tpr, thresholdsroc = roc\n",
        "# print(fpr, tpr, thresholdsroc,sep='\\n')\n",
        "# fpr = fpr.cpu()\n",
        "fpr = [t.cpu().numpy() for t in fpr]\n",
        "tpr = [t.cpu().numpy() for t in tpr]#tpr.cpu()\n",
        "thresholdsroc = [t.cpu().numpy() for t in thresholdsroc]#thresholdsroc.cpu()\n",
        "print(fpr, tpr, thresholdsroc,sep='\\n')\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# print(pr_curve)\n",
        "precision, recall, thresholdsPRC = pr_curve\n",
        "# print(precision, recall, thresholdsPRC, sep='\\n')\n",
        "precision = [t.cpu().numpy() for t in precision]#precision.cpu()\n",
        "recall = [t.cpu().numpy() for t in recall]#recall.cpu()\n",
        "thresholdsPRC = [t.cpu().numpy() for t in thresholdsPRC]#thresholdsPRC.cpu()\n",
        "print(precision, recall, thresholdsPRC, sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbJwLWFqnSQo",
        "outputId": "05553941-5cbb-48a5-b85c-529decc73ea8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ggplot in /usr/local/lib/python3.7/dist-packages (0.11.5)\n",
            "Requirement already satisfied: brewer2mpl in /usr/local/lib/python3.7/dist-packages (from ggplot) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from ggplot) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from ggplot) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ggplot) (1.21.6)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from ggplot) (0.10.2)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.7/dist-packages (from ggplot) (0.11.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from ggplot) (3.2.2)\n",
            "Requirement already satisfied: patsy>=0.4 in /usr/local/lib/python3.7/dist-packages (from ggplot) (0.5.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ggplot) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ggplot) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ggplot) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ggplot) (3.0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->ggplot) (4.2.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ggplot) (2022.1)\n",
            "Collecting tslib\n",
            "  Downloading tslib-1.8-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from tslib) (2022.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tslib) (1.15.0)\n",
            "Installing collected packages: tslib\n",
            "Successfully installed tslib-1.8\n"
          ]
        }
      ],
      "source": [
        "# !pip install ggplot\n",
        "# !pip install tslib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npUb1rl-sJwx"
      },
      "outputs": [],
      "source": [
        "fpr=fpr[0]\n",
        "tpr=tpr[0]\n",
        "# thresholdsroc=thresholdsroc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "U5l-hzs6h5x4",
        "outputId": "5e49ce03-380f-4e3e-98bd-56b297a38691"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(18388,) (18388,)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import sklearn.metrics as metrics\n",
        "import pandas\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "# probs = model.predict_proba(X_test)\n",
        "# preds = probs[:,1]\n",
        "# fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "print(np.shape(fpr), np.shape(tpr))\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()\n",
        "\n",
        "# # method II: ggplot\n",
        "# from ggplot import *\n",
        "# df = pd.DataFrame(dict(fpr = fpr, tpr = tpr))\n",
        "# ggplot(df, aes(x = 'fpr', y = 'tpr')) + geom_line() + geom_abline(linetype = 'dashed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "Sl9wlQ-ksXAN",
        "outputId": "2cf3ba4d-3924-4cf8-b497-3623e3c58f81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "####################################\n",
        "# The optimal cut off would be where tpr is high and fpr is low\n",
        "# tpr - (1-fpr) is zero or near to zero is the optimal cut off point\n",
        "####################################\n",
        "i = np.arange(len(tpr)) # index for df\n",
        "roc = pd.DataFrame({'fpr' : pd.Series(fpr, index=i),'tpr' : pd.Series(tpr, index = i), '1-fpr' : pd.Series(1-fpr, index = i), 'tf' : pd.Series(tpr - (1-fpr), index = i), 'thresholds' : pd.Series(thresholdsroc, index = i)})\n",
        "roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n",
        "\n",
        "# Plot tpr vs 1-fpr\n",
        "fig, ax = plt.subplots()\n",
        "plt.plot(roc['tpr'])\n",
        "plt.plot(roc['1-fpr'], color = 'red')\n",
        "plt.xlabel('1-False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic')\n",
        "ax.set_xticklabels([])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "l3-sIaM-tUnJ",
        "outputId": "7c1731e1-3f0b-4dec-ef69-92126f916a3c"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-120-919a19418daa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'tf'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpr\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'threshold'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthresholdsroc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mroc_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrocs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrocs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mibase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m                 \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;31m# create/copy the manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         raise ValueError(\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0;34m\"does not match length of index \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Length of values (5) does not match length of index (18388)"
          ]
        }
      ],
      "source": [
        "i = np.arange(len(tpr)) \n",
        "rocs = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(thresholdsroc, index=i)})\n",
        "roc_t = rocs.iloc[(rocs.tf-0).abs().argsort()[:1]]\n",
        "print(roc_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "id": "dDvxu8unpXy-",
        "outputId": "161c91a0-71c2-4d29-e085-e61bdc89b7ce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/shape_base.py:65: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ary = asanyarray(ary)\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-e1881cc6d992>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mlw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"darkorange\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"CNN (area = {:.3f})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9932\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#roc_auc))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"navy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"--\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1647\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1649\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1650\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request_autoscale_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36madd_line\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   1848\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1850\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_line_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1851\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_line%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_update_line_limits\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   1870\u001b[0m         \u001b[0mFigures\u001b[0m \u001b[0mout\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mlimit\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdating\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataLim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1871\u001b[0m         \"\"\"\n\u001b[0;32m-> 1872\u001b[0;31m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1873\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1874\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mget_path\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \"\"\"\n\u001b[1;32m   1026\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidy\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mrecache\u001b[0;34m(self, always)\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0malways\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m             \u001b[0mxconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_xunits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xorig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_unmasked_float_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxconv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36m_to_unmasked_float_array\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1315\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANT0lEQVR4nO3cYYjkd33H8ffHO1NpjKb0VpC706T00njYQtIlTRFqirZc8uDugUXuIFgleGAbKVWEFEuU+MiGWhCu1ZOKVdAYfSALntwDjQTEC7chNXgXItvTeheFrDHNk6Ax7bcPZtKdrneZf3Zndy/7fb/gYP7/+e3Mlx97752d2ZlUFZKk7e8VWz2AJGlzGHxJasLgS1ITBl+SmjD4ktSEwZekJqYGP8lnkzyZ5PuXuD5JPplkKcmjSW6c/ZiSpPUa8gj/c8CBF7n+VmDf+N9R4F/WP5YkadamBr+qHgR+/iJLDgGfr5FTwNVJXj+rASVJs7FzBrexGzg/cXxhfO6nqxcmOcrotwCuvPLKP7z++utncPeS1MfDDz/8s6qaW8vXziL4g1XVceA4wPz8fC0uLm7m3UvSy16S/1zr187ir3SeAPZOHO8Zn5MkXUZmEfwF4F3jv9a5GXimqn7t6RxJ0taa+pROki8BtwC7klwAPgK8EqCqPgWcAG4DloBngfds1LCSpLWbGvyqOjLl+gL+emYTSZI2hO+0laQmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqYlBwU9yIMnjSZaS3HWR69+Q5IEkjyR5NMltsx9VkrQeU4OfZAdwDLgV2A8cSbJ/1bK/B+6vqhuAw8A/z3pQSdL6DHmEfxOwVFXnquo54D7g0Ko1BbxmfPm1wE9mN6IkaRaGBH83cH7i+ML43KSPArcnuQCcAN5/sRtKcjTJYpLF5eXlNYwrSVqrWb1oewT4XFXtAW4DvpDk1267qo5X1XxVzc/Nzc3oriVJQwwJ/hPA3onjPeNzk+4A7geoqu8CrwJ2zWJASdJsDAn+aWBfkmuTXMHoRdmFVWt+DLwNIMmbGAXf52wk6TIyNfhV9TxwJ3ASeIzRX+OcSXJPkoPjZR8E3pvke8CXgHdXVW3U0JKkl27nkEVVdYLRi7GT5+6euHwWeMtsR5MkzZLvtJWkJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNTEo+EkOJHk8yVKSuy6x5p1JziY5k+SLsx1TkrReO6ctSLIDOAb8GXABOJ1koarOTqzZB/wd8JaqejrJ6zZqYEnS2gx5hH8TsFRV56rqOeA+4NCqNe8FjlXV0wBV9eRsx5QkrdeQ4O8Gzk8cXxifm3QdcF2S7yQ5leTAxW4oydEki0kWl5eX1zaxJGlNZvWi7U5gH3ALcAT4TJKrVy+qquNVNV9V83NzczO6a0nSEEOC/wSwd+J4z/jcpAvAQlX9qqp+CPyA0Q8ASdJlYkjwTwP7klyb5ArgMLCwas3XGD26J8kuRk/xnJvhnJKkdZoa/Kp6HrgTOAk8BtxfVWeS3JPk4HjZSeCpJGeBB4APVdVTGzW0JOmlS1VtyR3Pz8/X4uLilty3JL1cJXm4qubX8rW+01aSmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmBgU/yYEkjydZSnLXi6x7R5JKMj+7ESVJszA1+El2AMeAW4H9wJEk+y+y7irgb4CHZj2kJGn9hjzCvwlYqqpzVfUccB9w6CLrPgZ8HPjFDOeTJM3IkODvBs5PHF8Yn/s/SW4E9lbV11/shpIcTbKYZHF5efklDytJWrt1v2ib5BXAJ4APTltbVcerar6q5ufm5tZ715Kkl2BI8J8A9k4c7xmfe8FVwJuBbyf5EXAzsOALt5J0eRkS/NPAviTXJrkCOAwsvHBlVT1TVbuq6pqqugY4BRysqsUNmViStCZTg19VzwN3AieBx4D7q+pMknuSHNzoASVJs7FzyKKqOgGcWHXu7kusvWX9Y0mSZs132kpSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmhgU/CQHkjyeZCnJXRe5/gNJziZ5NMk3k7xx9qNKktZjavCT7ACOAbcC+4EjSfavWvYIMF9VfwB8FfiHWQ8qSVqfIY/wbwKWqupcVT0H3AccmlxQVQ9U1bPjw1PAntmOKUlaryHB3w2cnzi+MD53KXcA37jYFUmOJllMsri8vDx8SknSus30RdsktwPzwL0Xu76qjlfVfFXNz83NzfKuJUlT7Byw5glg78TxnvG5/yfJ24EPA2+tql/OZjxJ0qwMeYR/GtiX5NokVwCHgYXJBUluAD4NHKyqJ2c/piRpvaYGv6qeB+4ETgKPAfdX1Zkk9yQ5OF52L/Bq4CtJ/j3JwiVuTpK0RYY8pUNVnQBOrDp398Tlt894LknSjPlOW0lqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpoYFPwkB5I8nmQpyV0Xuf43knx5fP1DSa6Z9aCSpPWZGvwkO4BjwK3AfuBIkv2rlt0BPF1Vvwv8E/DxWQ8qSVqfIY/wbwKWqupcVT0H3AccWrXmEPBv48tfBd6WJLMbU5K0XjsHrNkNnJ84vgD80aXWVNXzSZ4Bfhv42eSiJEeBo+PDXyb5/lqG3oZ2sWqvGnMvVrgXK9yLFb+31i8cEvyZqarjwHGAJItVNb+Z93+5ci9WuBcr3IsV7sWKJItr/dohT+k8AeydON4zPnfRNUl2Aq8FnlrrUJKk2RsS/NPAviTXJrkCOAwsrFqzAPzl+PJfAN+qqprdmJKk9Zr6lM74Ofk7gZPADuCzVXUmyT3AYlUtAP8KfCHJEvBzRj8Upjm+jrm3G/dihXuxwr1Y4V6sWPNexAfiktSD77SVpCYMviQ1seHB92MZVgzYiw8kOZvk0STfTPLGrZhzM0zbi4l170hSSbbtn+QN2Ysk7xx/b5xJ8sXNnnGzDPg/8oYkDyR5ZPz/5LatmHOjJflskicv9V6ljHxyvE+PJrlx0A1X1Yb9Y/Qi738AvwNcAXwP2L9qzV8BnxpfPgx8eSNn2qp/A/fiT4HfHF9+X+e9GK+7CngQOAXMb/XcW/h9sQ94BPit8fHrtnruLdyL48D7xpf3Az/a6rk3aC/+BLgR+P4lrr8N+AYQ4GbgoSG3u9GP8P1YhhVT96KqHqiqZ8eHpxi952E7GvJ9AfAxRp/L9IvNHG6TDdmL9wLHquppgKp6cpNn3CxD9qKA14wvvxb4ySbOt2mq6kFGf/F4KYeAz9fIKeDqJK+fdrsbHfyLfSzD7kutqarngRc+lmG7GbIXk+5g9BN8O5q6F+NfUfdW1dc3c7AtMOT74jrguiTfSXIqyYFNm25zDdmLjwK3J7kAnADevzmjXXZeak+ATf5oBQ2T5HZgHnjrVs+yFZK8AvgE8O4tHuVysZPR0zq3MPqt78Ekv19V/7WlU22NI8Dnquofk/wxo/f/vLmq/merB3s52OhH+H4sw4ohe0GStwMfBg5W1S83abbNNm0vrgLeDHw7yY8YPUe5sE1fuB3yfXEBWKiqX1XVD4EfMPoBsN0M2Ys7gPsBquq7wKsYfbBaN4N6stpGB9+PZVgxdS+S3AB8mlHst+vztDBlL6rqmaraVVXXVNU1jF7POFhVa/7QqMvYkP8jX2P06J4kuxg9xXNuM4fcJEP24sfA2wCSvIlR8Jc3dcrLwwLwrvFf69wMPFNVP532RRv6lE5t3McyvOwM3It7gVcDXxm/bv3jqjq4ZUNvkIF70cLAvTgJ/HmSs8B/Ax+qqm33W/DAvfgg8Jkkf8voBdx3b8cHiEm+xOiH/K7x6xUfAV4JUFWfYvT6xW3AEvAs8J5Bt7sN90qSdBG+01aSmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElq4n8BzPZcum6w2goAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# plt.figure(1)\n",
        "# plt.plot([0, 1], [0, 1], 'k-')\n",
        "# plt.plot(fpr, tpr, label='CNN(area = {:.3f})'.format(0.9932))#roc_auc))\n",
        "# plt.xlabel('False positive rate')\n",
        "# plt.ylabel('True positive rate')\n",
        "# plt.title('ROC curve')\n",
        "# plt.legend(loc='best')\n",
        "# plt.show()\n",
        "\n",
        "# plt.figure(1)\n",
        "# lw = 2\n",
        "# plt.plot(fpr, tpr, color=\"darkorange\", label=\"CNN (area = {:.3f})\".format(0.9932))#roc_auc))\n",
        "# plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
        "# plt.xlim([0.0, 1.0])\n",
        "# plt.ylim([0.0, 1.05])\n",
        "# plt.xlabel('False positive rate')\n",
        "# plt.ylabel('True positive rate')\n",
        "# plt.title('ROC curve')\n",
        "# plt.legend(loc=\"lower right\")\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jub3zLRo2WLG"
      },
      "source": [
        "#Multiclass metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVDQlM4xdTsp",
        "outputId": "be859bcf-09c4-4f30-8574-dfb7199e0c6c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:01<00:00,  3.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Metrics on all data: \n",
            "Area Under ROC Curve: 0.5207756161689758\n",
            "Precision: 0.6461538672447205\n",
            "Recall: 0.6315789818763733\n",
            "F1 Score: 0.6221591234207153\n",
            "Accuracy: 0.6315789818763733\n",
            "Cohen kappa coefficient: 0.2631579041481018\n",
            "Confusion Matrix: tensor([[ 9, 10],\n",
            "        [ 4, 15]], device='cuda:0')\n",
            "Testing time 0:00:01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#-------------------------------------------------------------Run batches\n",
        "import time\n",
        "import datetime\n",
        "from tqdm import tqdm\n",
        "\n",
        "import itertools#for testing limit size\n",
        "# slicedDataloader = itertools.islice(data_loader, 1000)\n",
        "\n",
        "# batch = next(iter(dataloader_train))\n",
        "\n",
        "start_time = time.time()\n",
        "for idx, (samples_1, targets) in enumerate(tqdm(data_loader)):\n",
        "  input_tensor_cuda=samples_1.to(device)#.cuda()\n",
        "  output = model(input_tensor_cuda)\n",
        "\n",
        "  preds = output.detach()\n",
        "  # print(preds)\n",
        "  target = targets.to(device)\n",
        "  preds = preds[: , :realClassNumber]#remove extra classes ------------------------- (also adjust classes given to metrics to only 5)\n",
        "  # print(preds)\n",
        "  # metric on current batch\n",
        "  for key, metric in MultiClassMetrics.items():\n",
        "    metric(preds, target)\n",
        "\n",
        "# metric on all batches using custom accumulation\n",
        "metricsValues = {key:metric.compute() for key, metric in MultiClassMetrics.items()}\n",
        "\n",
        "print(f\"\\nMetrics on all data: \")\n",
        "# for metricsResult in metricsList:\n",
        "for key, metric in metricsValues.items():#Print results\n",
        "  print(f\"{key}: {metric}\")\n",
        "\n",
        "# Reseting internal state such that metric ready for new data\n",
        "for key, metric in MultiClassMetrics.items():\n",
        "  metric.reset()\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "print('Testing time {}'.format(total_time_str))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "id": "npwY3WKSTmCg",
        "outputId": "ba41b067-23a2-4b20-d7c6-8929f0ed3304"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1080x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "#Get the conv mat\n",
        "conf_mat = metricsValues[\"Confusion Matrix\"].to('cpu').numpy()\n",
        "\n",
        "\n",
        "plt.figure(figsize = (15,10))\n",
        "# Normalize it by row: for colouring\n",
        "# RowNormConvMat = conf_mat / conf_mat.astype(np.float).sum(axis=1)\n",
        "RowNormConvMat = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
        " \n",
        "# And see the result\n",
        "sns.heatmap(RowNormConvMat, annot= conf_mat, cmap='YlGnBu', fmt = \".3g\", cbar_kws={'label': 'Proportion of the predicted values of the correct class'})\n",
        "plt.xlabel(\"Predicted Classes\")\n",
        "plt.ylabel(\"Actual Classes\")\n",
        "plt.title(\"Confusion matrix\", fontsize = 20)\n",
        "plt.show()\n",
        "# sns.heatmap(conf_mat, annot=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SwinTorchMetrics.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "90d300cefea5f5a9b6f76537b38232b44d1908420b3927ee92dcc0b333035ada"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('swinEx')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
