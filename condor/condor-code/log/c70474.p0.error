/user/HS126/gb00538/anaconda3/envs/transformer-ssl-3090/lib/python3.7/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/aten/src/ATen/native/TensorShape.cpp:2228.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/user/HS126/gb00538/anaconda3/envs/transformer-ssl-3090/lib/python3.7/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/aten/src/ATen/native/TensorShape.cpp:2228.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/user/HS126/gb00538/anaconda3/envs/transformer-ssl-3090/lib/python3.7/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/aten/src/ATen/native/TensorShape.cpp:2228.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/user/HS126/gb00538/anaconda3/envs/transformer-ssl-3090/lib/python3.7/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/aten/src/ATen/native/TensorShape.cpp:2228.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Traceback (most recent call last):
  File "/user/HS126/gb00538/condor-examples/Mine/Transformer-SSL-3090-Pre/moby_main.py", line 246, in <module>
    main(config)
  File "/user/HS126/gb00538/condor-examples/Mine/Transformer-SSL-3090-Pre/moby_main.py", line 129, in main
    train_one_epoch(config, model, data_loader_train, optimizer, epoch, lr_scheduler)
  File "/user/HS126/gb00538/condor-examples/Mine/Transformer-SSL-3090-Pre/moby_main.py", line 154, in train_one_epoch
    loss = model(samples_1, samples_2)
  File "/user/HS126/gb00538/anaconda3/envs/transformer-ssl-3090/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/user/HS126/gb00538/anaconda3/envs/transformer-ssl-3090/lib/python3.7/site-packages/torch/nn/parallel/distributed.py", line 963, in forward
    output = self.module(*inputs[0], **kwargs[0])
  File "/user/HS126/gb00538/anaconda3/envs/transformer-ssl-3090/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/user/HS126/gb00538/condor-examples/Mine/Transformer-SSL-3090-Pre/models/moby.py", line 165, in forward
    self._dequeue_and_enqueue(proj_1_ng, proj_2_ng)
  File "/user/HS126/gb00538/anaconda3/envs/transformer-ssl-3090/lib/python3.7/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/user/HS126/gb00538/condor-examples/Mine/Transformer-SSL-3090-Pre/models/moby.py", line 114, in _dequeue_and_enqueue
    self.queue1[:, ptr:ptr + batch_size] = keys1.T
RuntimeError: The expanded size of the tensor (24) must match the existing size (32) at non-singleton dimension 1.  Target sizes: [256, 24].  Tensor sizes: [256, 32]
Traceback (most recent call last):
  File "/user/HS126/gb00538/condor-examples/Mine/Transformer-SSL-3090-Pre/moby_main.py", line 246, in <module>
    main(config)
  File "/user/HS126/gb00538/condor-examples/Mine/Transformer-SSL-3090-Pre/moby_main.py", line 129, in main
    train_one_epoch(config, model, data_loader_train, optimizer, epoch, lr_scheduler)
  File "/user/HS126/gb00538/condor-examples/Mine/Transformer-SSL-3090-Pre/moby_main.py", line 154, in train_one_epoch
    loss = model(samples_1, samples_2)
  File "/user/HS126/gb00538/anaconda3/envs/transformer-ssl-3090/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/user/HS126/gb00538/anaconda3/envs/transformer-ssl-3090/lib/python3.7/site-packages/torch/nn/parallel/distributed.py", line 963, in forward
    output = self.module(*inputs[0], **kwargs[0])
  File "/user/HS126/gb00538/anaconda3/envs/transformer-ssl-3090/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/user/HS126/gb00538/condor-examples/Mine/Transformer-SSL-3090-Pre/models/moby.py", line 165, in forward
    self._dequeue_and_enqueue(proj_1_ng, proj_2_ng)
  File "/user/HS126/gb00538/anaconda3/envs/transformer-ssl-3090/lib/python3.7/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/user/HS126/gb00538/condor-examples/Mine/Transformer-SSL-3090-Pre/models/moby.py", line 114, in _dequeue_and_enqueue
    self.queue1[:, ptr:ptr + batch_size] = keys1.T
RuntimeError: The expanded size of the tensor (24) must match the existing size (32) at non-singleton dimension 1.  Target sizes: [256, 24].  Tensor sizes: [256, 32]
Traceback (most recent call last):
  File "/user/HS126/gb00538/condor-examples/Mine/Transformer-SSL-3090-Pre/moby_main.py", line 246, in <module>
    main(config)
  File "/user/HS126/gb00538/condor-examples/Mine/Transformer-SSL-3090-Pre/moby_main.py", line 129, in main
    train_one_epoch(config, model, data_loader_train, optimizer, epoch, lr_scheduler)
  File "/user/HS126/gb00538/condor-examples/Mine/Transformer-SSL-3090-Pre/moby_main.py", line 154, in train_one_epoch
    loss = model(samples_1, samples_2)
  File "/user/HS126/gb00538/anaconda3/envs/transformer-ssl-3090/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/user/HS126/gb00538/anaconda3/envs/transformer-ssl-3090/lib/python3.7/site-packages/torch/nn/parallel/distributed.py", line 963, in forward
    output = self.module(*inputs[0], **kwargs[0])
  File "/user/HS126/gb00538/anaconda3/envs/transformer-ssl-3090/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/user/HS126/gb00538/condor-examples/Mine/Transformer-SSL-3090-Pre/models/moby.py", line 165, in forward
    self._dequeue_and_enqueue(proj_1_ng, proj_2_ng)
  File "/user/HS126/gb00538/anaconda3/envs/transformer-ssl-3090/lib/python3.7/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/user/HS126/gb00538/condor-examples/Mine/Transformer-SSL-3090-Pre/models/moby.py", line 114, in _dequeue_and_enqueue
    self.queue1[:, ptr:ptr + batch_size] = keys1.T
RuntimeError: The expanded size of the tensor (24) must match the existing size (32) at non-singleton dimension 1.  Target sizes: [256, 24].  Tensor sizes: [256, 32]
Traceback (most recent call last):
  File "/user/HS126/gb00538/condor-examples/Mine/Transformer-SSL-3090-Pre/moby_main.py", line 246, in <module>
    main(config)
  File "/user/HS126/gb00538/condor-examples/Mine/Transformer-SSL-3090-Pre/moby_main.py", line 129, in main
    train_one_epoch(config, model, data_loader_train, optimizer, epoch, lr_scheduler)
  File "/user/HS126/gb00538/condor-examples/Mine/Transformer-SSL-3090-Pre/moby_main.py", line 154, in train_one_epoch
    loss = model(samples_1, samples_2)
  File "/user/HS126/gb00538/anaconda3/envs/transformer-ssl-3090/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/user/HS126/gb00538/anaconda3/envs/transformer-ssl-3090/lib/python3.7/site-packages/torch/nn/parallel/distributed.py", line 963, in forward
    output = self.module(*inputs[0], **kwargs[0])
  File "/user/HS126/gb00538/anaconda3/envs/transformer-ssl-3090/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/user/HS126/gb00538/condor-examples/Mine/Transformer-SSL-3090-Pre/models/moby.py", line 165, in forward
    self._dequeue_and_enqueue(proj_1_ng, proj_2_ng)
  File "/user/HS126/gb00538/anaconda3/envs/transformer-ssl-3090/lib/python3.7/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/user/HS126/gb00538/condor-examples/Mine/Transformer-SSL-3090-Pre/models/moby.py", line 114, in _dequeue_and_enqueue
    self.queue1[:, ptr:ptr + batch_size] = keys1.T
RuntimeError: The expanded size of the tensor (24) must match the existing size (32) at non-singleton dimension 1.  Target sizes: [256, 24].  Tensor sizes: [256, 32]
/user/HS126/gb00538/anaconda3/envs/transformer-ssl-3090/lib/python3.7/site-packages/torch/distributed/launch.py:186: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  FutureWarning,
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 23) of binary: /user/HS126/gb00538/anaconda3/envs/transformer-ssl-3090/bin/python
Traceback (most recent call last):
  File "/user/HS126/gb00538/anaconda3/envs/transformer-ssl-3090/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/user/HS126/gb00538/anaconda3/envs/transformer-ssl-3090/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/user/HS126/gb00538/anaconda3/envs/transformer-ssl-3090/lib/python3.7/site-packages/torch/distributed/launch.py", line 193, in <module>
    main()
  File "/user/HS126/gb00538/anaconda3/envs/transformer-ssl-3090/lib/python3.7/site-packages/torch/distributed/launch.py", line 189, in main
    launch(args)
  File "/user/HS126/gb00538/anaconda3/envs/transformer-ssl-3090/lib/python3.7/site-packages/torch/distributed/launch.py", line 174, in launch
    run(args)
  File "/user/HS126/gb00538/anaconda3/envs/transformer-ssl-3090/lib/python3.7/site-packages/torch/distributed/run.py", line 718, in run
    )(*cmd_args)
  File "/user/HS126/gb00538/anaconda3/envs/transformer-ssl-3090/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/user/HS126/gb00538/anaconda3/envs/transformer-ssl-3090/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 247, in launch_agent
    failures=result.failures,
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/user/HS126/gb00538/condor-examples/Mine/Transformer-SSL-3090-Pre/moby_main.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2022-04-20_09:02:41
  host      : gb00538-70474.0-nain.eps.surrey.ac.uk
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 24)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2022-04-20_09:02:41
  host      : gb00538-70474.0-nain.eps.surrey.ac.uk
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 25)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2022-04-20_09:02:41
  host      : gb00538-70474.0-nain.eps.surrey.ac.uk
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 26)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2022-04-20_09:02:41
  host      : gb00538-70474.0-nain.eps.surrey.ac.uk
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 23)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
